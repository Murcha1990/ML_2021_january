{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кластеризация\n",
    "\n",
    "## Задача 1. Кластеризация на простом примере.\n",
    "Рассмотрим простой пример. Сначала сгенерируем точки из трех визуально различающихся кластеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pylab as plt\n",
    "%pylab inline\n",
    "\n",
    "\n",
    "X = np.zeros((150, 2))\n",
    "\n",
    "np.random.seed(seed=42)\n",
    "X[:50, 0] = np.random.normal(loc=0.0, scale=.3, size=50)\n",
    "X[:50, 1] = np.random.normal(loc=0.0, scale=.3, size=50)\n",
    "\n",
    "X[50:100, 0] = np.random.normal(loc=2.0, scale=.5, size=50)\n",
    "X[50:100, 1] = np.random.normal(loc=-1.0, scale=.2, size=50)\n",
    "\n",
    "X[100:150, 0] = np.random.normal(loc=-1.0, scale=.2, size=50)\n",
    "X[100:150, 1] = np.random.normal(loc=2.0, scale=.5, size=50)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=1)\n",
    "kmeans.fit(X)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(X[...,0], X[...,1], s=50, cmap='viridis')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим kmeans. Покрасим точки из каждого кластера в свой цвет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=1)\n",
    "kmeans.fit(X)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(X[:,0], X[:,1], c=kmeans.labels_, s=50, cmap='viridis')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим иерархическую кластеризацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "distance_mat = pdist(X) # pdist посчитает нам верхний треугольник матрицы попарных расстояний\n",
    "\n",
    "Z = hierarchy.linkage(distance_mat, 'single') # linkage — реализация агломеративного алгоритма\n",
    "plt.figure(figsize=(10, 5))\n",
    "dn = hierarchy.dendrogram(Z, color_threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В зависимости от величины color_threshold меняются кластеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in [0.1, 0.3, 0.5, 0.7]:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    dn = hierarchy.dendrogram(Z, color_threshold=threshold)\n",
    "    plt.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 2. кластеризация игроков NBA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba = pd.read_csv(\"nba_2019.csv\")\n",
    "nba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените kmeans с 5ю кластерами только к числовым столбцам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "numeric_cols = nba._get_numeric_data().dropna(axis=1)\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируйте данные с помощью метода главных компонент с n_components = 2:\n",
    "\n",
    "    1) Примените метод главных компонент\n",
    "    \n",
    "    2) Нарисуйте полученные точки на плоскости, раскрашенные в цвета, соответствующие кластерам (см. пример выше)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Мы видим, что kmeans разбил игроков на 5 практически не пересекающихся, но лежащих близко друг к другу кластеров.***\n",
    "\n",
    "* Попытаемся понять, на основании каких факторов объекты были разбиты на кластеры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какое смысловое значение несут кластеры.\n",
    "\n",
    "1) Визуализируйте точки в осях nba['PTS'] (total points) и nba['AST'] (total assistances) и раскрасьте их в цвета кластеров.\n",
    "\n",
    "2) Визуализируйте точки в осях nba['Age'] (age) и nba['MP'] (minutes played) и раскрасьте их в цвета кластеров.\n",
    "\n",
    "Подпишите оси."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация центров кластеров (центроидов)\n",
    "\n",
    "Метод `sklearn.KMeans` содержит параметры `n_init` (число запусков из различных начальных приближений) и `init`. Есть три способа инициализации центроидов:\n",
    "- `k-means++` – \"умная\" инициализация центроидов для ускорения сходимости.\n",
    "- `random` – случайная инициализация центроидов.\n",
    "- `ndarray` – заданная инициализация центроидов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 3. Сжатие изображений с K-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread('cat.jpg')[..., 1]\n",
    "plt.figure(figsize = (15, 9))\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from scipy.stats import randint\n",
    "\n",
    "X = img.reshape((-1, 1))\n",
    "\n",
    "for n in np.arange(5, 100, 5):\n",
    "    print('N = ', n)\n",
    "    k_means = MiniBatchKMeans(n_clusters=n)\n",
    "    k_means.fit(X) \n",
    "    values = k_means.cluster_centers_\n",
    "    labels = k_means.labels_\n",
    "    img_compressed = values[labels].reshape(img.shape)\n",
    "    plt.figure(figsize = (5, 3))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_compressed, cmap = 'gray');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмите любую фотографию (можно работать с той же) и подберите минимальное число кластеров, которое визуально не ухудшает качество изображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 4. Нахождение тем в текстах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Применим KMeans для кластеризации текстов из 4 новостных категорий.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "from time import time\n",
    "\n",
    "categories = [\n",
    "    'talk.politics.misc',\n",
    "    'talk.religion.misc',\n",
    "    'comp.graphics',\n",
    "    'sci.space']\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories)\n",
    "\n",
    "dataset = fetch_20newsgroups(subset='all', categories=categories,\n",
    "                             shuffle=True, random_state=42)\n",
    "\n",
    "print(\"%d documents\" % len(dataset.data))\n",
    "print(\"%d categories\" % len(dataset.target_names))\n",
    "\n",
    "labels = dataset.target\n",
    "true_k = np.unique(labels).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Закодируем тексты с помощью TF-IDF признаков.**\n",
    "\n",
    "![How](tf-idf.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting features from the training dataset using a sparse vectorizer\")\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, max_features=1300,\n",
    "                             min_df=2, stop_words='english') \n",
    "\n",
    "X = vectorizer.fit_transform(dataset.data)\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**И применим к получившимся векторам метод $k$ средних."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "\n",
    "print(\"Clustering sparse data with %s\" % km)\n",
    "t0 = time()\n",
    "km.fit(X)\n",
    "\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выведем слова, соответствующие самым весомым компонентам центров кластеров.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % (i + 1), end='')\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Мы видим, что алгоритм разделил документы на кластеры, которые приблизительно соответствуют четырем заявленным темам. Однако внутри кластеров есть много неточностей, т.е. слов, не относящихся к заявленным темам.***\n",
    "\n",
    "Как оценить качество полученной кластеризации?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики качества кластеризации\n",
    "\n",
    "* Внешние метрики – используют информацию об истинных метках объектов\n",
    "\n",
    "* Внутренние метрики – оценивают качество кластеризации, основываясь только на наборе данных.\n",
    "\n",
    "### Внешние метрики:\n",
    "\n",
    "**1. Adjusted Rand Index (ARI)** - это *доля объектов, для которых исходное (правильные метки) и полученное (кластеры) разбиения согласованы. Выражает похожесть двух различных разбиений выборки*.\n",
    "\n",
    "$$ARI \\in [-1;1]$$\n",
    "\n",
    "$ARI>0$ – разбиения похожи ($ARI=1$ – совпадают)\n",
    "\n",
    "$ARI\\approx 0$ – случайные разбиения\n",
    "\n",
    "$ARI<0$ – непохожие разбиения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(labels, km.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Adjusted Mutual Information (AMI, взаимная информация)** -* измеряет долю информации, общей для обоих разбиений: насколько информация об одном из них уменьшает неопределенность относительно другого.*  \n",
    "\n",
    "$$AMI \\in [0;1]$$\n",
    "\n",
    "Чем ближе $AMI$ к $1$, тем более похожи разбиения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Adjusted mutual info score: %.3f\"\n",
    "      % metrics.adjusted_mutual_info_score(labels, km.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Гомогенность (Homogeneity), Полнота (Completeness), V-мера (V-measure):**\n",
    "* *Гомогенность (H) измеряет, насколько каждый кластер состоит из объектов одного класса, т.е. насколько однородны объекты внутри кластера.*\n",
    "* *Полнота (C) измеряет, насколько объекты одного класса относятся к одному кластеру.*\n",
    "    \n",
    "$$H \\in [0;1], C \\in [0;1].$$\n",
    "\n",
    "Большие значения гомогенности и полноты соответствуют более точной кластеризации.\n",
    "\n",
    "* *V-мера - среднее гармоническое гомогенности и полноты, используется, если хотим анализировать один показатель вместо двух. V-мера показывает, насколько два разбиения схожи.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важно!**\n",
    "\n",
    "***Гомогенность, полнота и V-мера не нормализованы (как ARI и AMI), т.е. они зависят от числа кластеров!***\n",
    "\n",
    "* При большом числе кластеров и малом числе объектов лучше использовать ARI и AMI.\n",
    "* При более 1000 объектов и числе кластеров меньше 10 проблема не так сильно выражена, поэтому её можно игнорировать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Внутренняя метрика:\n",
    "(не требует знания истинных меток)\n",
    "\n",
    "**Силуэт (S, silhouette)** - *показывает, насколько среднее расстояние до объектов своего кластера отличается от среднего расстояния до объектов других кластеров.*\n",
    "\n",
    "$$S \\in [-1;1]$$\n",
    "\n",
    "* $𝑆$ близкий к $-1$ – плохие (разрозненные) кластеризации\n",
    "* $S\\approx 0$ – кластеры накладываются друг на друга\n",
    "* $𝑆$ близкий к $1$ – четко выраженные кластеры\n",
    "\n",
    "***С помощью силуэта можно выбирать число кластеров $𝑘$ (если оно заранее неизвестно) – выбирается $𝑘$, для которого метрика максимальна.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, km.labels_, sample_size=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 5. Кластеризация рукописных цифр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "X, y = digits.data, digits.target\n",
    "Im = digits.images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите на экран первые 20 цифр (в цветовой схеме 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите kmeans с десятью кластерами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите на экран метрики качества кластеризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуем центры получившихся кластеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(2, 5)\n",
    "for ax, center in zip(axes.ravel(), model.cluster_centers_):\n",
    "    ax.matshow(center.reshape(8, 8), cmap=plt.cm.gray)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластеризация получилась довольно качественной. Визуализируем наши объекты (изображения цифр) как точки на двумерной плоскости.\n",
    "\n",
    "Визуализируйте данные с помощью PCA с двумя компонентами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем данные с помощью t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(random_state=17)\n",
    "\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y,\n",
    "            edgecolor='none', alpha=0.7, s=40,\n",
    "            cmap=plt.cm.get_cmap('nipy_spectral', 10))\n",
    "plt.colorbar()\n",
    "plt.title('MNIST. t-SNE projection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полезные ссылки\n",
    "- <a href=\"https://en.wikipedia.org/wiki/K-means_clustering\">k-means</a> на Википедии\n",
    "- <a href=\"https://habr.com/ru/post/208496/\">Статья</a> про нечеткую кластеризацию на Хабрахабре\n",
    "- <a href=\"https://scikit-learn.org/stable/modules/clustering.html\">обзор</a> методов кластеризации в sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "\n",
    "В этом задании мы попрактикуемся в методах снижения размерности и кластеризации данных. \n",
    "\n",
    "Мы будем работать с набором данных Samsung Human Activity Recognition. Скачайте данные по ссылке https://yadi.sk/d/_WFxgSIuBF06Rg. Данные поступают с акселерометров и гироскопов мобильных телефонов Samsung Galaxy S3, также известен вид активности человека с телефоном в кармане – ходил ли он, стоял, лежал, сидел или шел вверх/вниз по лестнице.\n",
    "\n",
    "Представим, что вид активности нам неизвестнен, и попробуем кластеризовать людей чисто на основе имеющихся признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(['seaborn-darkgrid'])\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "RANDOM_STATE = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.loadtxt(\"samsung_train.txt\")\n",
    "y_train = np.loadtxt(\"samsung_train_labels.txt\").astype(int)\n",
    "\n",
    "X_test = np.loadtxt(\"samsung_test.txt\")\n",
    "y_test = np.loadtxt(\"samsung_test_labels.txt\").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для кластеризации нам не нужен вектор ответов. Объедините обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "X = \n",
    "y ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти метки соответствуют:\n",
    "\n",
    "1 - ходьбе,\n",
    "2 - подъему вверх по лестнице,\n",
    "3 - спуску по лестнице,\n",
    "4 - сидению,\n",
    "5 - стоянию,\n",
    "6 - лежанию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отмасштабируйте выборку с помощью StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "scaler = \n",
    "X_scaled ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Понижаем размерность с помощью PCA, оставляя столько компонент, сколько нужно для того, чтобы объяснить как минимум 90% дисперсии исходных (отмасштабированных) данных. Используйте отмасштабированную выборку и зафиксируйте random_state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "pca = \n",
    "X_pca ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируйте данные в проекции на первые две главные компоненты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "plt.scatter(, , c=y, s=20, cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделайте кластеризацию данных методом KMeans, обучив модель на данных со сниженной за счет PCA размерностью. В данном случае нужно искать 6 кластеров (так как у нас 6 классов).\n",
    "\n",
    "Параметры:\n",
    "\n",
    "n_clusters = n_classes (число уникальных меток целевого класса)\n",
    "\n",
    "n_init = 100\n",
    "\n",
    "random_state = RANDOM_STATE (для воспроизводимости результата)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируйте данные в проекции на первые две главные компоненты. Раскрасьте точки в соответствии с полученными метками кластеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите на экран значения метрик качества кластеризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем сделать кластеризацию с помощью AgglomerativeClustering (https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = AgglomerativeClustering(n_clusters=n_classes, \n",
    "                             linkage='ward').fit(X_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите метрики качества для полученного разбиения на кластеры. Сравните с kmeans. Запишите выводы!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте применить другие методы кластеризации из sklearn. Также вычислите метрики качества и сделайте вывод о том, какой метод сработал лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "name": "lesson8_part1_kmeans.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
