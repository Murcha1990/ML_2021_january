{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решающие деревья, решающие леса и градиентный бустинг."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Решающее дерево vs решающий лес. \n",
    "\n",
    "Будем сравнивать эти алгоритмы на примере задачи регрессии: задачи предсказания стоимости домов в Бостоне."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data = load_boston()\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = data.data\n",
    "y_full = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_full[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем оценивать качество алгоритмов по кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model_lin = LinearRegression()\n",
    "\n",
    "score = cross_val_score(model_lin, X_full, y_full, cv=3, scoring='r2').mean()\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1.\n",
    "\n",
    "Посмотрите на качество решающего дерева на кросс-валидации. Запустите ячейку несколько раз и посмотрите, меняется ли качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.\n",
    "\n",
    "Посмотрите на качество случайного леса на кросс-валидации. Запустите ячейку несколько раз и посмотрите, меняется ли качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберём параметры у случайного леса:\n",
    "    \n",
    "    * n_estimators - число деревьев в лесе\n",
    "    * max_depth - максимальная глубина деревьев\n",
    "    * max_features - максимальное число признаков для построения каждого дерева\n",
    "    * min_samples_split - минимальное число объектов, необходимое для разбиения внутренней вершины\n",
    "    \n",
    "и другие, см. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "\n",
    "Самый важный параметр - число деревьев в лесе. Начнём с него.\n",
    "\n",
    "### Задание 3. \n",
    "\n",
    "Постройте лес из 10, 100, 500 и 1000 деревьев и посмотрите на r2 на кросс-валидации.\n",
    "\n",
    "Примените цикл по количеству деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [10, 100, 500, 1000, 10000]:\n",
    "    print('n_estimators:', n)\n",
    "    \n",
    "    model_rf = #your code here\n",
    "\n",
    "    score = #your code here\n",
    "\n",
    "    print('r2:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что чем больше деревьев в лесе, тем дольше он обучается. Однако качество алгоритма при 1000 и 10000 деревьев различается незначительно. Добавим в предыдущий цикл время работы алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "for n in [10, 100, 500, 1000, 10000]:\n",
    "    print('n_estimators:', n)\n",
    "    model_rf = RandomForestRegressor(n_estimators=n)\n",
    "\n",
    "    score = cross_val_score(model_rf, X_full, y_full, cv=3, scoring='r2').mean()\n",
    "\n",
    "    t_end = time()\n",
    "    print('time:', t_end-t_start)\n",
    "    print('r2:', score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решающий лес устроим таким образом, что чем больше деревьев в лесе, тем лучше качество предсказания. Однако, начиная с некоторого количества деревьев, качество увеличивается незначительно. А время, затрачиваемое на обучение алгоритма, увеличивается с увеличением числа деревьев. Построим график качества алгоритма в зависимости от количества деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from time import time\n",
    "\n",
    "r2_list = []\n",
    "time_list = []\n",
    "\n",
    "n_list = np.arange(10,2000,100)\n",
    "\n",
    "for n in tqdm(n_list):\n",
    "    model_rf = RandomForestRegressor(n_estimators=n)\n",
    "\n",
    "    t_start = time()\n",
    "\n",
    "    score = cross_val_score(model_rf, X_full, y_full, cv=3, scoring='r2').mean()\n",
    "\n",
    "    t_end = time()\n",
    "\n",
    "    r2_list.append(score)\n",
    "    time_list.append(t_end-t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pylab as plt\n",
    "%pylab inline\n",
    "\n",
    "plot(n_list, r2_list, '-o')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(n_list, time_list, '-o')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать лес с 600 деревьями.\n",
    "\n",
    "Далее будем подбирать параметры max_depth, max_features и min_samples_split с помощью функции GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_rf = RandomForestRegressor(n_estimators=600, n_jobs=-1, random_state=123)\n",
    "\n",
    "params = {'max_features': [None, 'log2', 'sqrt'], \n",
    "          'max_depth': [2, 4, 6, 8, 10, 20, 50]}\n",
    "\n",
    "gs = GridSearchCV(model_rf,\n",
    "                  params,\n",
    "                  cv=3,\n",
    "                  scoring='r2',\n",
    "                  n_jobs=-1)\n",
    "gs.fit(X_full, y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_estimator_, gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4. \n",
    "\n",
    "Попробуйте одновременно подбрать max_features, max_depth и min_samples_leaf. Последний параметр ищите по списку [1, 5, 10, 15, 20].\n",
    "\n",
    "Улучшилось ли качество алгоритма при одновременном подборе трех параметров?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_estimator_, gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Решающий лес vs градиентный бустинг.\n",
    "\n",
    "Теперь будем решать задачу классификации ([Kaggle: Predicting a Biological Response](https://www.kaggle.com/c/bioresponse))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "print(data.shape)\n",
    "X = data.iloc[:, 1:].values\n",
    "y = data.iloc[:, 0].values\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.8, random_state=241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y[y==0]), len(y[y==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5.\n",
    "\n",
    "Посмотрите на качество решающего леса с 10 деревьями на кросс-валидации (здесь метрика - accuracy, её можно не передавать в функцию cross_val_score, так как она там стоит по умолчанию для задачи классификации)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.\n",
    "\n",
    "Посмотрите на качество градиентного бустинга с 10 деревьями на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуем графики качества леса на тренировочной и тестовой выборках в зависимости от числа деревьев. Также нарисуем график времени работы алгоритма от числа деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from time import time\n",
    "\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "time_list = []\n",
    "\n",
    "n_list = np.arange(10,250,20)\n",
    "\n",
    "for n in tqdm(n_list):\n",
    "    model_rf = RandomForestClassifier(n_estimators=n)\n",
    "\n",
    "    t_start = time()\n",
    "    model_rf.fit(Xtrain, ytrain)\n",
    "\n",
    "    pred_train = model_rf.predict(Xtrain)\n",
    "    acc_train.append(accuracy_score(ytrain, pred_train))\n",
    "    \n",
    "    pred_test = model_rf.predict(Xtest)\n",
    "    acc_test.append(accuracy_score(ytest, pred_test))\n",
    "\n",
    "    t_end = time()\n",
    "\n",
    "    time_list.append(t_end-t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(12, 4))\n",
    "subplot(1, 3, 1)\n",
    "plot(n_list, acc_train, label='RF_train')\n",
    "plt.legend()\n",
    "plt.title('Train')\n",
    "plt.subplot(1, 3, 2)\n",
    "plot(n_list, acc_test, label='RF_test')\n",
    "plt.legend()\n",
    "plt.title('Test')\n",
    "plt.subplot(1, 3, 3)\n",
    "plot(n_list, time_list, label='RF_time')\n",
    "plt.legend()\n",
    "plt.title('Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 7.\n",
    "\n",
    "Теперь посмотрим, как меняется качество бустинга при увеличении числа деревьев. \n",
    "\n",
    "Постройте аналогичные графики, но для градиентного бустинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что у бустинга ошибка на Train всё время уменьшается, а ошибка на Test начинает расти, начиная с некоторого количества деревьев. То есть, начиная с этого числа деревьев алгоритм переобучается. Значит, нам надо остановиться на \n",
    "некотором числе деревьев, которому на графике ошибки на тесте соответствует наименьшая ошибка.\n",
    "\n",
    "### Задание 8. \n",
    "\n",
    "После выбора числа деревьев остальные параметры у бустинга можно подбирать с помощью GridSearchCV.\n",
    "Подберите max_features, max_depth и min_samples_leaf для бустинга с помощью GridSearchCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_estimator_, gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод.\n",
    "\n",
    "И решающий лес, и градиентный бустинг - это мощные ансамблевые алгоритмы, которые при должной настройке параметров показывают хорошее качество работы. Но надо помнить, что градиентный бустинг имеет склонность к переобучению с увеличением числа деревьев, и аккуратно подбирать число деревьев для алгоритма. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
